Building DAG of jobs...
Using shell: /usr/bin/bash
Provided cores: 1 (use --cores to define parallelism)
Rules claiming more threads will be scaled down.
Job stats:
job           count    min threads    max threads
----------  -------  -------------  -------------
all               1              1              1
genome            1              1              1
single            4              1              1
single_pre        4              1              1
total            10              1              1


[Wed Apr 10 15:30:43 2024]
rule genome:
    input: /work/frasergen/backup/3d/project/Interactome/231661_homo_sapiens_20240223/05.personal/analysis_washu_20240410/00.longest_gtf/hg19_mRNA_genename.gtf
    output: /work/frasergen/backup/3d/project/Interactome/231661_homo_sapiens_20240223/05.personal/analysis_washu_20240410/01.genome/work.sh
    jobid: 1
    resources: tmpdir=/tmp

[Wed Apr 10 15:30:52 2024]
Finished job 1.
1 of 10 steps (10%) done

[Wed Apr 10 15:30:52 2024]
rule single_pre:
    output: /work/frasergen/backup/3d/project/Interactome/231661_homo_sapiens_20240223/05.personal/analysis_washu_20240410/02.single_pre/CapHiC-control-1/work.sh
    jobid: 6
    wildcards: spl=CapHiC-control-1
    resources: tmpdir=/tmp

Shutting down, this might take some time.
Exiting because a job execution failed. Look above for error message
Complete log: /work/frasergen/3D/work/shaojie/script/HiC/washU/upload/.snakemake/log/2024-04-10T153034.401705.snakemake.log
