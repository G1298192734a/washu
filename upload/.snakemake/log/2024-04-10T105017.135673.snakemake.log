Building DAG of jobs...
Using shell: /usr/bin/bash
Provided cores: 1 (use --cores to define parallelism)
Rules claiming more threads will be scaled down.
Job stats:
job           count    min threads    max threads
----------  -------  -------------  -------------
all               1              1              1
genome            1              1              1
get_gtf           1              1              1
multi             1              1              1
multi_pre         1              1              1
single            4              1              1
single_pre        4              1              1
total            13              1              1


[Wed Apr 10 10:50:27 2024]
rule get_gtf:
    output: /work/frasergen/backup/3d/project/Interactome/231661_homo_sapiens_20240223/05.personal/analysis_washu_20240410/00.longest_gtf/work.sh
    jobid: 2
    resources: tmpdir=/tmp

[Wed Apr 10 10:50:37 2024]
Finished job 2.
1 of 13 steps (8%) done

[Wed Apr 10 10:50:37 2024]
rule genome:
    input: /work/frasergen/backup/3d/project/Interactome/231661_homo_sapiens_20240223/05.personal/analysis_washu_20240410/00.longest_gtf/work.sh
    output: /work/frasergen/backup/3d/project/Interactome/231661_homo_sapiens_20240223/05.personal/analysis_washu_20240410/01.genome/work.sh
    jobid: 1
    resources: tmpdir=/tmp

[Wed Apr 10 10:50:43 2024]
Finished job 1.
2 of 13 steps (15%) done

[Wed Apr 10 10:50:43 2024]
rule single_pre:
    output: /work/frasergen/backup/3d/project/Interactome/231661_homo_sapiens_20240223/05.personal/analysis_washu_20240410/02.single_pre/CapHiC-test-1/work.sh
    jobid: 4
    wildcards: spl=CapHiC-test-1
    resources: tmpdir=/tmp

Shutting down, this might take some time.
Exiting because a job execution failed. Look above for error message
Complete log: /work/frasergen/3D/work/shaojie/script/HiC/washU/upload/.snakemake/log/2024-04-10T105017.135673.snakemake.log
